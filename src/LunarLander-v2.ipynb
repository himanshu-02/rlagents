{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "577caf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn                        #To handle layers.\n",
    "import torch.nn.functional as F              #For value activation function.\n",
    "import torch.optim as optim                  #For adam optimizer\n",
    "import numpy as np\n",
    "\n",
    "import gym\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e403f4",
   "metadata": {},
   "source": [
    "This implementation uses an Agent that has a Deep Q-Learning network to train the LunarLander-v2 enviornment.\n",
    "Uses linear layers as the enviornment is an eight element vector observation \n",
    "\\[Horizontal Coordinate, Vertical Coordinate, Horizontal Speed, Vertical Speed, Angle, Angular Speed, 1 if first leg has contact else 0, 1 if second leg has contact, else 0]\\\n",
    "\n",
    "The landing pad is always at coordinates (0,0). The coordinates are the first two numbers in the state vector.\n",
    "Reward for moving from the top of the screen to the landing pad and zero speed is about 100..140 points.\n",
    "If the lander moves away from the landing pad it loses reward. The episode finishes if the lander crashes or\n",
    "comes to rest, receiving an additional -100 or +100 points. Each leg with ground contact is +10 points.\n",
    "Firing the main engine is -0.3 points each frame. Firing the side engine is -0.03 points each frame.\n",
    "Solved is 200 points.\n",
    "Landing outside the landing pad is possible. Fuel is infinite, so an agent can learn to fly and then land\n",
    "on its first attempt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2534f5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepQNetwork(nn.Module):\n",
    "    def __init__(self, lr, input_dims, fc1_dims, fc2_dims, n_actions):\n",
    "        super(DeepQNetwork, self).__init__()\n",
    "        self.input_dims = input_dims\n",
    "        self.fc1_dims = fc1_dims\n",
    "        self.fc2_dims = fc2_dims\n",
    "        self.n_actions = n_actions\n",
    "        self.fc1 = nn.Linear(*self.input_dims, self.fc1_dims)\n",
    "        self.fc2 = nn.Linear(self.fc1_dims, self.fc2_dims)\n",
    "        self.fc3 = nn.Linear(self.fc2_dims, self.n_actions)\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        self.loss = nn.MSELoss()              #Mean squared error loss\n",
    "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "    \n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        actions = self.fc3(x)\n",
    "         \n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a41e961",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, gamma, epsilon, lr, input_dims, batch_size, n_actions, max_mem_size=1000000, eps_end=0.01, eps_dec=5e-4):\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.eps_min = eps_end\n",
    "        self.eps_dec = eps_dec\n",
    "        self.lr = lr\n",
    "        self.action_space = [i for i in range(n_actions)]\n",
    "        self.mem_size = max_mem_size\n",
    "        self.batch_size = batch_size\n",
    "        self.mem_cntr = 0\n",
    "        \n",
    "        self.Q_eval = DeepQNetwork(self.lr, n_actions=n_actions, input_dims=input_dims, fc1_dims=256, fc2_dims=256)\n",
    "                                                                                            #Evaluation network\n",
    "        \n",
    "        self.state_memory = np.zeros((self.mem_size, *input_dims), dtype=np.float32)\n",
    "                                                                                #Storing state memory as named array \n",
    "        self.new_state_memory = np.zeros((self.mem_size, *input_dims), dtype=np.float32)\n",
    "                                                                                #Storing new state memory as named array\n",
    "        #TD update rule requires the value of current state, next state; and the reward it recieved\n",
    "        \n",
    "        self.action_memory = np.zeros(self.mem_size, dtype=np.int32)\n",
    "        self.reward_memory = np.zeros(self.mem_size, dtype=np.float32)\n",
    "        self.terminal_memory = np.zeros(self.mem_size, dtype=np.bool)\n",
    "        \n",
    "    def store_transition(self, state, action, reward, state_, done):\n",
    "        index = self.mem_cntr % self.mem_size\n",
    "        self.state_memory[index] = state\n",
    "        self.new_state_memory[index] = state_\n",
    "        self.reward_memory[index] = reward\n",
    "        self.action_memory[index] = action\n",
    "        self.terminal_memory[index] = done \n",
    "        \n",
    "        self.mem_cntr += 1\n",
    "        \n",
    "    def choose_action(self, observation):                                        #choose action using epsilon \n",
    "        if np.random.random() > self.epsilon:\n",
    "            state = T.tensor([observation]).to(self.Q_eval.device)\n",
    "            actions = self.Q_eval.forward(state)\n",
    "            action = T.argmax(actions).item()\n",
    "        else:\n",
    "            action = np.random.choice(self.action_space)\n",
    "        \n",
    "        return action\n",
    "    \n",
    "    def learn(self):\n",
    "        if self.mem_cntr < self.batch_size:\n",
    "            return                                      #If atleast the batch size of memory is not filled, do actions at random\n",
    "        \n",
    "        self.Q_eval.optimizer.zero_grad()\n",
    "        \n",
    "        max_mem = min(self.mem_cntr, self.mem_size)\n",
    "        batch = np.random.choice(max_mem, self.batch_size, replace=False)\n",
    "        \n",
    "        batch_index = np.arange(self.batch_size, dtype=np.int32)\n",
    "        \n",
    "        state_batch = T.tensor(self.state_memory[batch]).to(self.Q_eval.device)\n",
    "        new_state_batch = T.tensor(self.new_state_memory[batch]).to(self.Q_eval.device)\n",
    "        reward_batch= T.tensor(self.reward_memory[batch]).to(self.Q_eval.device)\n",
    "        terminal_batch = T.tensor(self.terminal_memory[batch]).to(self.Q_eval.device)\n",
    "                                                        #Converting np array subset of memory into pytorch tensor.\n",
    "        \n",
    "        action_batch = self.action_memory[batch]\n",
    "        \n",
    "        q_eval = self.Q_eval.forward(state_batch)[batch_index, action_batch]\n",
    "        q_next = self.Q_eval.forward(new_state_batch)\n",
    "        q_next[terminal_batch] = 0.0\n",
    "        \n",
    "        q_target = reward_batch + self.gamma * T.max(q_next, dim=1)[0] \n",
    "        \n",
    "        loss = self.Q_eval.loss(q_target, q_eval).to(self.Q_eval.device)\n",
    "        loss.backward()\n",
    "        self.Q_eval.optimizer.step()\n",
    "        \n",
    "        self.epsilon = self.epsilon - self.eps_dec if self.epsilon > self.eps_min \\\n",
    "                        else self.eps_min\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a2a3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hrc/anaconda3/envs/myenv/lib/python3.7/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode  0 score -141.71 average score -141.71 epsilon 0.99\n",
      "episode  1 score -234.72 average score -188.22 epsilon 0.93\n",
      "episode  2 score -37.81 average score -138.08 epsilon 0.88\n",
      "episode  3 score -246.12 average score -165.09 epsilon 0.85\n",
      "episode  4 score -164.31 average score -164.93 epsilon 0.78\n",
      "episode  5 score 10.21 average score -135.74 epsilon 0.73\n",
      "episode  6 score -327.83 average score -163.18 epsilon 0.68\n",
      "episode  7 score 24.63 average score -139.71 epsilon 0.65\n",
      "episode  8 score -491.37 average score -178.78 epsilon 0.60\n",
      "episode  9 score -154.98 average score -176.40 epsilon 0.55\n",
      "episode  10 score -159.84 average score -174.90 epsilon 0.48\n",
      "episode  11 score -61.84 average score -165.47 epsilon 0.43\n",
      "episode  12 score -85.78 average score -159.34 epsilon 0.38\n",
      "episode  13 score -113.39 average score -156.06 epsilon 0.28\n",
      "episode  14 score -188.23 average score -158.21 epsilon 0.22\n",
      "episode  15 score -82.74 average score -153.49 epsilon 0.08\n",
      "episode  16 score -196.73 average score -156.03 epsilon 0.01\n",
      "episode  17 score -38.08 average score -149.48 epsilon 0.01\n",
      "episode  18 score -72.16 average score -145.41 epsilon 0.01\n",
      "episode  19 score -102.96 average score -143.29 epsilon 0.01\n",
      "episode  20 score -54.91 average score -139.08 epsilon 0.01\n",
      "episode  21 score -68.27 average score -135.86 epsilon 0.01\n",
      "episode  22 score -105.74 average score -134.55 epsilon 0.01\n",
      "episode  23 score -158.01 average score -135.53 epsilon 0.01\n",
      "episode  24 score -94.85 average score -133.90 epsilon 0.01\n",
      "episode  25 score -151.07 average score -134.56 epsilon 0.01\n",
      "episode  26 score -232.31 average score -138.18 epsilon 0.01\n",
      "episode  27 score -95.97 average score -136.67 epsilon 0.01\n",
      "episode  28 score -86.46 average score -134.94 epsilon 0.01\n",
      "episode  29 score 225.11 average score -122.94 epsilon 0.01\n",
      "episode  30 score 37.85 average score -117.75 epsilon 0.01\n",
      "episode  31 score -239.42 average score -121.56 epsilon 0.01\n",
      "episode  32 score -22.64 average score -118.56 epsilon 0.01\n",
      "episode  33 score -54.61 average score -116.68 epsilon 0.01\n",
      "episode  34 score -136.47 average score -117.24 epsilon 0.01\n",
      "episode  35 score -10.39 average score -114.28 epsilon 0.01\n",
      "episode  36 score -46.11 average score -112.43 epsilon 0.01\n",
      "episode  37 score -70.65 average score -111.33 epsilon 0.01\n",
      "episode  38 score -119.78 average score -111.55 epsilon 0.01\n",
      "episode  39 score -250.13 average score -115.01 epsilon 0.01\n",
      "episode  40 score -254.65 average score -118.42 epsilon 0.01\n",
      "episode  41 score -465.88 average score -126.69 epsilon 0.01\n",
      "episode  42 score -21.54 average score -124.25 epsilon 0.01\n",
      "episode  43 score -59.42 average score -122.77 epsilon 0.01\n",
      "episode  44 score -144.83 average score -123.26 epsilon 0.01\n",
      "episode  45 score -150.34 average score -123.85 epsilon 0.01\n",
      "episode  46 score -239.34 average score -126.31 epsilon 0.01\n",
      "episode  47 score -88.57 average score -125.52 epsilon 0.01\n",
      "episode  48 score 222.31 average score -118.43 epsilon 0.01\n",
      "episode  49 score -301.28 average score -122.08 epsilon 0.01\n",
      "episode  50 score -260.75 average score -124.80 epsilon 0.01\n",
      "episode  51 score -368.97 average score -129.50 epsilon 0.01\n",
      "episode  52 score -159.19 average score -130.06 epsilon 0.01\n",
      "episode  53 score -129.48 average score -130.05 epsilon 0.01\n",
      "episode  54 score -338.51 average score -133.84 epsilon 0.01\n",
      "episode  55 score 269.05 average score -126.64 epsilon 0.01\n",
      "episode  56 score 89.04 average score -122.86 epsilon 0.01\n",
      "episode  57 score -88.91 average score -122.27 epsilon 0.01\n",
      "episode  58 score -115.81 average score -122.16 epsilon 0.01\n",
      "episode  59 score -60.04 average score -121.13 epsilon 0.01\n",
      "episode  60 score -449.22 average score -126.51 epsilon 0.01\n",
      "episode  61 score -119.91 average score -126.40 epsilon 0.01\n",
      "episode  62 score -111.94 average score -126.17 epsilon 0.01\n",
      "episode  63 score -136.89 average score -126.34 epsilon 0.01\n",
      "episode  64 score -80.46 average score -125.63 epsilon 0.01\n",
      "episode  65 score -260.47 average score -127.68 epsilon 0.01\n",
      "episode  66 score -79.84 average score -126.96 epsilon 0.01\n",
      "episode  67 score -151.26 average score -127.32 epsilon 0.01\n",
      "episode  68 score -119.46 average score -127.21 epsilon 0.01\n",
      "episode  69 score -121.71 average score -127.13 epsilon 0.01\n",
      "episode  70 score -141.82 average score -127.33 epsilon 0.01\n",
      "episode  71 score -90.06 average score -126.82 epsilon 0.01\n",
      "episode  72 score -139.63 average score -126.99 epsilon 0.01\n",
      "episode  73 score -345.57 average score -129.95 epsilon 0.01\n",
      "episode  74 score -14.60 average score -128.41 epsilon 0.01\n",
      "episode  75 score -114.16 average score -128.22 epsilon 0.01\n",
      "episode  76 score -120.13 average score -128.11 epsilon 0.01\n",
      "episode  77 score -111.57 average score -127.90 epsilon 0.01\n",
      "episode  78 score -358.44 average score -130.82 epsilon 0.01\n",
      "episode  79 score -128.86 average score -130.80 epsilon 0.01\n",
      "episode  80 score -102.24 average score -130.44 epsilon 0.01\n",
      "episode  81 score -113.08 average score -130.23 epsilon 0.01\n",
      "episode  82 score -91.01 average score -129.76 epsilon 0.01\n",
      "episode  83 score -122.09 average score -129.67 epsilon 0.01\n",
      "episode  84 score -52.53 average score -128.76 epsilon 0.01\n",
      "episode  85 score -94.61 average score -128.36 epsilon 0.01\n",
      "episode  86 score -97.32 average score -128.01 epsilon 0.01\n",
      "episode  87 score -117.87 average score -127.89 epsilon 0.01\n",
      "episode  88 score -79.99 average score -127.35 epsilon 0.01\n",
      "episode  89 score -134.85 average score -127.44 epsilon 0.01\n",
      "episode  90 score -133.36 average score -127.50 epsilon 0.01\n",
      "episode  91 score -80.90 average score -127.00 epsilon 0.01\n",
      "episode  92 score -97.13 average score -126.67 epsilon 0.01\n",
      "episode  93 score -137.23 average score -126.79 epsilon 0.01\n",
      "episode  94 score -88.55 average score -126.38 epsilon 0.01\n",
      "episode  95 score -77.30 average score -125.87 epsilon 0.01\n",
      "episode  96 score -62.65 average score -125.22 epsilon 0.01\n",
      "episode  97 score -85.71 average score -124.82 epsilon 0.01\n",
      "episode  98 score -67.48 average score -124.24 epsilon 0.01\n",
      "episode  99 score -80.83 average score -123.80 epsilon 0.01\n",
      "episode  100 score -89.35 average score -123.28 epsilon 0.01\n",
      "episode  101 score -112.90 average score -122.06 epsilon 0.01\n",
      "episode  102 score -63.94 average score -122.32 epsilon 0.01\n",
      "episode  103 score -42.40 average score -120.29 epsilon 0.01\n",
      "episode  104 score -59.36 average score -119.24 epsilon 0.01\n",
      "episode  105 score -48.40 average score -119.82 epsilon 0.01\n",
      "episode  106 score -59.10 average score -117.14 epsilon 0.01\n",
      "episode  107 score -86.68 average score -118.25 epsilon 0.01\n",
      "episode  108 score -111.77 average score -114.45 epsilon 0.01\n",
      "episode  109 score -26.23 average score -113.17 epsilon 0.01\n",
      "episode  110 score -62.44 average score -112.19 epsilon 0.01\n",
      "episode  111 score -36.10 average score -111.93 epsilon 0.01\n",
      "episode  112 score -81.22 average score -111.89 epsilon 0.01\n",
      "episode  113 score -32.36 average score -111.08 epsilon 0.01\n",
      "episode  114 score -94.40 average score -110.14 epsilon 0.01\n",
      "episode  115 score -63.85 average score -109.95 epsilon 0.01\n",
      "episode  116 score -61.20 average score -108.60 epsilon 0.01\n",
      "episode  117 score -79.97 average score -109.01 epsilon 0.01\n",
      "episode  118 score -63.06 average score -108.92 epsilon 0.01\n",
      "episode  119 score -102.38 average score -108.92 epsilon 0.01\n",
      "episode  120 score -57.76 average score -108.95 epsilon 0.01\n",
      "episode  121 score -26.78 average score -108.53 epsilon 0.01\n",
      "episode  122 score -100.80 average score -108.48 epsilon 0.01\n",
      "episode  123 score -41.58 average score -107.32 epsilon 0.01\n",
      "episode  124 score -59.68 average score -106.97 epsilon 0.01\n",
      "episode  125 score -84.92 average score -106.30 epsilon 0.01\n",
      "episode  126 score -80.50 average score -104.79 epsilon 0.01\n",
      "episode  127 score -91.82 average score -104.74 epsilon 0.01\n",
      "episode  128 score -87.39 average score -104.75 epsilon 0.01\n",
      "episode  129 score -36.90 average score -107.37 epsilon 0.01\n",
      "episode  130 score -146.76 average score -109.22 epsilon 0.01\n",
      "episode  131 score -61.32 average score -107.44 epsilon 0.01\n",
      "episode  132 score -83.70 average score -108.05 epsilon 0.01\n",
      "episode  133 score -62.15 average score -108.13 epsilon 0.01\n",
      "episode  134 score -53.39 average score -107.29 epsilon 0.01\n",
      "episode  135 score -24.94 average score -107.44 epsilon 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode  136 score -78.36 average score -107.76 epsilon 0.01\n",
      "episode  137 score -75.95 average score -107.82 epsilon 0.01\n",
      "episode  138 score -58.10 average score -107.20 epsilon 0.01\n",
      "episode  139 score -74.32 average score -105.44 epsilon 0.01\n",
      "episode  140 score -31.32 average score -103.21 epsilon 0.01\n",
      "episode  141 score -30.38 average score -98.85 epsilon 0.01\n",
      "episode  142 score -47.61 average score -99.11 epsilon 0.01\n",
      "episode  143 score -58.12 average score -99.10 epsilon 0.01\n",
      "episode  144 score -126.18 average score -98.91 epsilon 0.01\n",
      "episode  145 score -56.28 average score -97.97 epsilon 0.01\n",
      "episode  146 score -60.85 average score -96.19 epsilon 0.01\n",
      "episode  147 score -104.57 average score -96.35 epsilon 0.01\n",
      "episode  148 score -300.18 average score -101.57 epsilon 0.01\n",
      "episode  149 score -322.57 average score -101.79 epsilon 0.01\n",
      "episode  150 score -74.48 average score -99.92 epsilon 0.01\n",
      "episode  151 score -25.22 average score -96.49 epsilon 0.01\n",
      "episode  152 score -59.52 average score -95.49 epsilon 0.01\n",
      "episode  153 score -20.59 average score -94.40 epsilon 0.01\n",
      "episode  154 score -85.65 average score -91.87 epsilon 0.01\n",
      "episode  155 score -43.07 average score -94.99 epsilon 0.01\n",
      "episode  156 score -63.57 average score -96.52 epsilon 0.01\n",
      "episode  157 score -86.38 average score -96.49 epsilon 0.01\n",
      "episode  158 score -92.67 average score -96.26 epsilon 0.01\n",
      "episode  159 score -105.14 average score -96.71 epsilon 0.01\n",
      "episode  160 score -67.68 average score -92.90 epsilon 0.01\n",
      "episode  161 score 163.67 average score -90.06 epsilon 0.01\n",
      "episode  162 score -63.60 average score -89.58 epsilon 0.01\n",
      "episode  163 score -82.69 average score -89.04 epsilon 0.01\n",
      "episode  164 score -27.01 average score -88.50 epsilon 0.01\n",
      "episode  165 score -36.26 average score -86.26 epsilon 0.01\n",
      "episode  166 score -31.76 average score -85.78 epsilon 0.01\n",
      "episode  167 score -94.07 average score -85.21 epsilon 0.01\n",
      "episode  168 score -52.10 average score -84.53 epsilon 0.01\n",
      "episode  169 score -12.03 average score -83.44 epsilon 0.01\n",
      "episode  170 score -84.04 average score -82.86 epsilon 0.01\n",
      "episode  171 score -37.46 average score -82.33 epsilon 0.01\n",
      "episode  172 score -35.26 average score -81.29 epsilon 0.01\n",
      "episode  173 score -28.92 average score -78.12 epsilon 0.01\n",
      "episode  174 score -11.79 average score -78.09 epsilon 0.01\n",
      "episode  175 score -11.57 average score -77.07 epsilon 0.01\n",
      "episode  176 score -49.52 average score -76.36 epsilon 0.01\n",
      "episode  177 score -35.08 average score -75.60 epsilon 0.01\n",
      "episode  178 score 3.92 average score -71.97 epsilon 0.01\n",
      "episode  179 score -38.03 average score -71.07 epsilon 0.01\n",
      "episode  180 score -43.49 average score -70.48 epsilon 0.01\n",
      "episode  181 score -31.50 average score -69.66 epsilon 0.01\n",
      "episode  182 score -14.02 average score -68.89 epsilon 0.01\n",
      "episode  183 score -1.82 average score -67.69 epsilon 0.01\n",
      "episode  184 score -68.69 average score -67.85 epsilon 0.01\n",
      "episode  185 score -24.71 average score -67.15 epsilon 0.01\n",
      "episode  186 score -21.88 average score -66.40 epsilon 0.01\n",
      "episode  187 score -50.46 average score -65.72 epsilon 0.01\n",
      "episode  188 score -10.11 average score -65.02 epsilon 0.01\n",
      "episode  189 score -81.52 average score -64.49 epsilon 0.01\n",
      "episode  190 score -33.11 average score -63.49 epsilon 0.01\n",
      "episode  191 score -18.81 average score -62.87 epsilon 0.01\n",
      "episode  192 score -40.94 average score -62.31 epsilon 0.01\n",
      "episode  193 score -38.23 average score -61.32 epsilon 0.01\n",
      "episode  194 score -52.56 average score -60.96 epsilon 0.01\n",
      "episode  195 score -54.16 average score -60.73 epsilon 0.01\n",
      "episode  196 score -47.47 average score -60.57 epsilon 0.01\n",
      "episode  197 score -9.90 average score -59.82 epsilon 0.01\n",
      "episode  198 score 1.44 average score -59.13 epsilon 0.01\n",
      "episode  199 score -49.60 average score -58.81 epsilon 0.01\n",
      "episode  200 score -17.74 average score -58.10 epsilon 0.01\n",
      "episode  201 score 2.64 average score -56.94 epsilon 0.01\n",
      "episode  202 score -37.33 average score -56.68 epsilon 0.01\n",
      "episode  203 score -6.44 average score -56.32 epsilon 0.01\n",
      "episode  204 score -25.15 average score -55.97 epsilon 0.01\n",
      "episode  205 score -56.79 average score -56.06 epsilon 0.01\n",
      "episode  206 score -22.44 average score -55.69 epsilon 0.01\n",
      "episode  207 score -28.06 average score -55.11 epsilon 0.01\n",
      "episode  208 score -39.44 average score -54.38 epsilon 0.01\n",
      "episode  209 score -12.91 average score -54.25 epsilon 0.01\n",
      "episode  210 score -48.93 average score -54.11 epsilon 0.01\n",
      "episode  211 score -81.54 average score -54.57 epsilon 0.01\n",
      "episode  212 score -62.68 average score -54.38 epsilon 0.01\n",
      "episode  213 score -44.42 average score -54.50 epsilon 0.01\n",
      "episode  214 score -43.55 average score -54.00 epsilon 0.01\n",
      "episode  215 score -60.91 average score -53.97 epsilon 0.01\n",
      "episode  216 score -145.43 average score -54.81 epsilon 0.01\n",
      "episode  217 score -18.59 average score -54.19 epsilon 0.01\n",
      "episode  218 score -52.81 average score -54.09 epsilon 0.01\n",
      "episode  219 score -19.87 average score -53.27 epsilon 0.01\n",
      "episode  220 score -18.19 average score -52.87 epsilon 0.01\n",
      "episode  221 score -37.31 average score -52.98 epsilon 0.01\n",
      "episode  222 score -56.17 average score -52.53 epsilon 0.01\n",
      "episode  223 score -16.04 average score -52.27 epsilon 0.01\n",
      "episode  224 score -143.77 average score -53.12 epsilon 0.01\n",
      "episode  225 score -12.92 average score -52.40 epsilon 0.01\n",
      "episode  226 score 8.58 average score -51.50 epsilon 0.01\n",
      "episode  227 score -41.17 average score -51.00 epsilon 0.01\n",
      "episode  228 score 21.66 average score -49.91 epsilon 0.01\n",
      "episode  229 score -53.25 average score -50.07 epsilon 0.01\n",
      "episode  230 score -12.87 average score -48.73 epsilon 0.01\n",
      "episode  231 score -198.81 average score -50.11 epsilon 0.01\n",
      "episode  232 score 3.29 average score -49.24 epsilon 0.01\n",
      "episode  233 score -32.01 average score -48.94 epsilon 0.01\n",
      "episode  234 score -85.76 average score -49.26 epsilon 0.01\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    env = gym.make('LunarLander-v2')\n",
    "    agent = Agent(gamma=0.99, epsilon=1.0, batch_size=64, n_actions=4,\n",
    "                     eps_end=0.01, input_dims=[8], lr=0.001)\n",
    "    scores, eps_history = [], []\n",
    "    n_games = 500\n",
    "    \n",
    "    for i in range(n_games):\n",
    "        score = 0\n",
    "        done = False\n",
    "        observation = env.reset()\n",
    "        while not done:\n",
    "            if i >= (n_games - 5) or i<5:\n",
    "                env.render()\n",
    "            action = agent.choose_action(observation)\n",
    "            observation_, reward, done, info = env.step(action)\n",
    "            score += reward\n",
    "            agent.store_transition(observation, action, reward, \n",
    "                                  observation_, done)\n",
    "            agent.learn()\n",
    "            observation = observation_\n",
    "        scores.append(score)\n",
    "        eps_history.append(agent.epsilon)\n",
    "        \n",
    "        avg_score = np.mean(scores[-100:])\n",
    "        \n",
    "        print('episode ', i, 'score %.2f' % score, \n",
    "                  'average score %.2f' % avg_score,\n",
    "                  'epsilon %.2f' % agent.epsilon)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32eac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "        done = False\n",
    "        observation = env.reset()\n",
    "        while not done:\n",
    "            env.render()\n",
    "            action = agent.choose_action(observation)\n",
    "            observation_, reward, done, info = env.step(action)\n",
    "            observation = observation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e6f39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d64ab79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
