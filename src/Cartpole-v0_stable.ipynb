{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2008c920",
   "metadata": {},
   "source": [
    "# 1. importing dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9e5f2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "from gym import wrappers\n",
    "from time import time # just to have timestamps in the files\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv #Train model on multiple envs at the same time\n",
    "from stable_baselines3.common.evaluation import evaluate_policy #avg reward over episode and get S.D.\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f2a3ea",
   "metadata": {},
   "source": [
    "Description:\n",
    "        A pole is attached by an un-actuated joint to a cart, which moves along\n",
    "        a frictionless track. The pendulum starts upright, and the goal is to\n",
    "        prevent it from falling over by increasing and reducing the cart's\n",
    "        velocity.\n",
    "    Source:\n",
    "        This environment corresponds to the version of the cart-pole problem\n",
    "        described by Barto, Sutton, and Anderson\n",
    "    Observation:\n",
    "        Type: Box(4)\n",
    "        Num     Observation               Min                     Max\n",
    "        0       Cart Position             -4.8                    4.8\n",
    "        1       Cart Velocity             -Inf                    Inf\n",
    "        2       Pole Angle                -0.418 rad (-24 deg)    0.418 rad (24 deg)\n",
    "        3       Pole Angular Velocity     -Inf                    Inf\n",
    "    Actions:\n",
    "        Type: Discrete(2)\n",
    "        Num   Action\n",
    "        0     Push cart to the left\n",
    "        1     Push cart to the right\n",
    "        Note: The amount the velocity that is reduced or increased is not\n",
    "        fixed; it depends on the angle the pole is pointing. This is because\n",
    "        the center of gravity of the pole increases the amount of energy needed\n",
    "        to move the cart underneath it\n",
    "    Reward:\n",
    "        Reward is 1 for every step taken, including the termination step\n",
    "    Starting State:\n",
    "        All observations are assigned a uniform random value in \\[-0.05..0.05]\n",
    "    Episode Termination:\n",
    "        Pole Angle is more than 12 degrees.\n",
    "        Cart Position is more than 2.4 (center of the cart reaches the edge of\n",
    "        the display).\n",
    "        Episode length is greater than 200.\n",
    "        Solved Requirements:\n",
    "        Considered solved when the average return is greater than or equal to\n",
    "        195.0 over 100 consecutive trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6487e97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = 'CartPole-v0'\n",
    "env = gym.make(environment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b21ca7d",
   "metadata": {},
   "source": [
    "# Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fad063",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "episodes = 100\n",
    "scores=[]\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "        scores.append(score)\n",
    "    if(score>50):\n",
    "        print(\"Episode:{} Score:{}\" .format(episode, score))\n",
    "print(max(scores))        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3435f0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a4963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b465f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space.sample() # gives discrete/random output 0 or 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b475fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observation_space # refer https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py\n",
    "# Cart position, Cart velocity, Pole angle, Pole angular velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afca1454",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observation_space.sample() # example of observation_space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f800f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.step(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb7a2cd",
   "metadata": {},
   "source": [
    "# 3. Train model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05ae50da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(environment_name)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "model = PPO('MlpPolicy', env, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48c1b032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 788  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 2    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 539         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009228478 |\n",
      "|    clip_fraction        | 0.0958      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | -0.00158    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.85        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 55.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 499         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008512514 |\n",
      "|    clip_fraction        | 0.0484      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.666      |\n",
      "|    explained_variance   | 0.0715      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 36.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 466         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007452307 |\n",
      "|    clip_fraction        | 0.0765      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.634      |\n",
      "|    explained_variance   | 0.21        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.7        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    value_loss           | 53.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 462         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008343551 |\n",
      "|    clip_fraction        | 0.071       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.608      |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30          |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 57.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009767543 |\n",
      "|    clip_fraction        | 0.0985      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.594      |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.6        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    value_loss           | 64.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 452          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049899425 |\n",
      "|    clip_fraction        | 0.033        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.594       |\n",
      "|    explained_variance   | 0.386        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 19.1         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    value_loss           | 65.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 451          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057100942 |\n",
      "|    clip_fraction        | 0.0345       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.58        |\n",
      "|    explained_variance   | 0.616        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 31.7         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0061      |\n",
      "|    value_loss           | 54.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 450          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066678817 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.577       |\n",
      "|    explained_variance   | 0.405        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 31.6         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.000836    |\n",
      "|    value_loss           | 80.3         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 449        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 45         |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00766767 |\n",
      "|    clip_fraction        | 0.0493     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.576     |\n",
      "|    explained_variance   | 0.838      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 16.7       |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.00405   |\n",
      "|    value_loss           | 34         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7fb5b9d77150>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd06cf4",
   "metadata": {},
   "source": [
    "# 4. Save model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36de2884",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hrc/anaconda3/envs/myenv/lib/python3.7/site-packages/stable_baselines3/common/save_util.py:276: UserWarning: Path 'Training/Saved Models' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n"
     ]
    }
   ],
   "source": [
    "PPO_path = os.path.join('Training', 'Saved Models', 'PPO_cartpole_20k')\n",
    "model.save(PPO_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d97339",
   "metadata": {},
   "source": [
    "# 5. Evaluate model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c30a515",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hrc/anaconda3/envs/myenv/lib/python3.7/site-packages/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(200.0, 0.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes = 10, render = True) # Two args and Two keyword args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8838d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35996724",
   "metadata": {},
   "source": [
    "# 6. Final testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "163835e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:[200.]\n",
      "Episode:2 Score:[200.]\n",
      "Episode:3 Score:[200.]\n",
      "Episode:4 Score:[200.]\n",
      "Episode:5 Score:[200.]\n",
      "Episode:6 Score:[200.]\n",
      "Episode:7 Score:[200.]\n",
      "Episode:8 Score:[200.]\n",
      "Episode:9 Score:[200.]\n",
      "Episode:10 Score:[200.]\n"
     ]
    }
   ],
   "source": [
    "episodes = 10\n",
    "for episode in range(1, episodes+1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "    print(\"Episode:{} Score:{}\" .format(episode, score))\n",
    "env.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8610eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
