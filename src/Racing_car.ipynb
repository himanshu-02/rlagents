{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15e80e29",
   "metadata": {},
   "source": [
    "# 1. Import dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "112086b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94027513",
   "metadata": {},
   "source": [
    "Description:\n",
    "    The reward is -0.1 every frame and +1000/N for every track tile visited, where \n",
    "    N is the total number of tiles visited in the track. For example, if you have\n",
    "    finished in 732 frames, your reward is 1000 - 0.1*732 = 926.8 points.\n",
    "    The game is solved when the agent consistently gets 900+ points. The generated\n",
    "    track is random every episode.\n",
    "    The episode finishes when all the tiles are visited. The car also can go\n",
    "    outside of the PLAYFIELD -  that is far off the track, then it will get -100\n",
    "    and die.\n",
    "    Some indicators are shown at the bottom of the window along with the state RGB\n",
    "    buffer. From left to right: the true speed, four ABS sensors, the steering\n",
    "    wheel position and gyroscope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "611e361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = \"CarRacing-v0\"\n",
    "env = gym.make(environment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ff7796",
   "metadata": {},
   "source": [
    "# 2. Test environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83d8b0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1219..1528 -> 309-tiles track\n",
      "Episode:1 Score:-35.06493506493556\n"
     ]
    }
   ],
   "source": [
    "episodes = 1\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bf7c5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0c17dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(3,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c01af60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00138051,  0.38237363,  0.07358833], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a668b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(96, 96, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b70daef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[137, 178, 150],\n",
       "        [162,  28, 173],\n",
       "        [226,  82, 101],\n",
       "        ...,\n",
       "        [157, 129, 106],\n",
       "        [139, 163, 192],\n",
       "        [113,  89, 197]],\n",
       "\n",
       "       [[147,  83,  89],\n",
       "        [ 46,  41,  87],\n",
       "        [231, 151,   6],\n",
       "        ...,\n",
       "        [116,  56, 114],\n",
       "        [ 95,  76, 115],\n",
       "        [155, 139, 103]],\n",
       "\n",
       "       [[ 67, 149,  88],\n",
       "        [188,  34, 187],\n",
       "        [  0,   5, 122],\n",
       "        ...,\n",
       "        [ 66, 152, 121],\n",
       "        [185, 226,  33],\n",
       "        [115, 239, 125]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[195,   8, 133],\n",
       "        [112,  44,  20],\n",
       "        [193,  62, 115],\n",
       "        ...,\n",
       "        [167, 144,  79],\n",
       "        [ 86,  94,  78],\n",
       "        [254, 208,  65]],\n",
       "\n",
       "       [[ 87, 205,  20],\n",
       "        [219, 246, 243],\n",
       "        [209, 127, 178],\n",
       "        ...,\n",
       "        [193,   7, 191],\n",
       "        [ 13,  94, 108],\n",
       "        [152, 228, 113]],\n",
       "\n",
       "       [[ 94, 147, 137],\n",
       "        [234,  91, 236],\n",
       "        [ 61, 240, 120],\n",
       "        ...,\n",
       "        [203,  39, 129],\n",
       "        [130,  23, 254],\n",
       "        [ 16, 227,  19]]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93ab56c",
   "metadata": {},
   "source": [
    "# 3. Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275319ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = make_vec_env(\"CarRacing-v0\", n_envs = 4, seed = 0)\n",
    "# env = VecFrameStack(env, n_stack=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c56d1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "log_path = os.path.join('Training', 'Logs')\n",
    "model = PPO(\"CnnPolicy\", env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742e9c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps = 2000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a7036c",
   "metadata": {},
   "source": [
    "# 4. Save model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c236de67",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_path = os.path.join('Training', 'Saved Models', 'PPO_2m_Driving_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4666d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(ppo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616f1605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bdea46b",
   "metadata": {},
   "source": [
    "# 5. Load and evaluate model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5881fa17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "model=PPO.load(ppo_path,env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fcc80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf12c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6306c1fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join('Training', 'Saved Models', 'PPO_2m_Driving_model')\n",
    "model = PPO.load(model_path, env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "843dacb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hrc/anaconda3/envs/myenv/lib/python3.7/site-packages/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1195..1498 -> 303-tiles track\n",
      "Track generation: 1128..1414 -> 286-tiles track\n",
      "Track generation: 1127..1411 -> 284-tiles track\n",
      "Track generation: 1145..1435 -> 290-tiles track\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([698.013219319284, 528.0701851025224, 412.3674968332052], [1000, 1000, 1000])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes = 3, return_episode_rewards = True, render = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee24741",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 10\n",
    "for episode in range(1, episodes+1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "    print(\"Episode:{} Score:{}\" .format(episode, score))\n",
    "env.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e772601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cda5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy??\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
